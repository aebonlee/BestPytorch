{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Du8CrcJpOu7O"
   },
   "source": [
    "## 실전 2 : 액션 데이터를 활용한 인간의 동작 분류\n",
    "### 2-1. UCF101 데이터셋을 활용하여 사용하고자 하는 모델에 맞게 커스터마이징한다.\n",
    "\n",
    "#https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/software-and-datasets/mpii-human-pose-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2VEKS_POu7R"
   },
   "source": [
    "## 학습 목표\n",
    "----\n",
    "- Action Recognition 모델에서 요구하는 포맷에 맞게 이미지 데이터를 전처리할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Action Recognition 모델의 데이터셋이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILQhDVZ-Ou7V"
   },
   "source": [
    "## `영상 데이터셋 커스텀`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 동영상은 이미지의 연속입니다. 즉, 영상은 이미지의 '덩어리' 일 뿐이라는거죠.\n",
    "- 따라서, 영상을 데이터셋으로 만든다고 해서 특별한 처리가 추가되는 것은 아닙니다.\n",
    "- 영상을 개별 이미지로 쪼개고, 개별 이미지에 대한 전처리를 수행하고, 이를 하나의 단위로 묶어 데이터셋으로 만드는 과정일 뿐입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms #torchvision -> 딥러닝(이미지) 수행하는 클래스 이름 #transform 이미지를 조절\n",
    "from PIL import Image #-> 이미지를 표현할 수 있는 파이썬 라이브러리 \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.7177, grad_fn=<SumBackward0>)\n",
      "x의 기울기: tensor([[ 1.4107,  0.7004, -1.9872,  1.1932,  1.1365],\n",
      "        [ 0.3790, -0.5483,  0.6982,  0.3506,  0.5293],\n",
      "        [ 1.5671, -2.1525,  0.9341,  0.5595, -2.4579],\n",
      "        [-0.0990, -0.8848, -0.6238,  0.1522, -0.1320],\n",
      "        [ 1.3113, -0.3902,  0.3870,  0.8419,  0.2033]])\n",
      "w의 기울기: tensor([[-0.9066, -0.6513,  0.9476, -0.3739,  0.2793],\n",
      "        [ 0.5310,  0.2594,  0.8583,  1.1222, -2.2979],\n",
      "        [ 0.4863,  0.9470, -0.5443,  0.1771, -0.1681],\n",
      "        [-0.2080,  2.0822, -0.8380, -1.2704, -0.3327],\n",
      "        [-0.2491, -0.8742,  0.5619,  0.4893,  1.3312]])\n"
     ]
    }
   ],
   "source": [
    "class CustomData(Dataset):\n",
    "    def __init__(self, path, transform):\n",
    "        self.image_path = path     #전체 이미지 경로를 저장\n",
    "        self.transform = transform #이미지에 대해 일괄적으로 적용할 '전처리'\n",
    "        \n",
    "    def __len__(self):\n",
    "        #if (이미지수 == 라벨수) return 이미지 수\n",
    "        return len(self.image_path)\n",
    "\n",
    "    #텐서 형태로 변환된 이미지를 돌려줌\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.image_path[idx]\n",
    "        image = Image.open(image)    #해당 경로에서 이미지를 읽어 옴\n",
    "\n",
    "        if self.transform is not None:\n",
    "            result = self.transform(image)\n",
    "\n",
    "        #csv,파일 이름 등을 이용해서 데이터에 맞는 라벨을 반환\n",
    "        label = 1 \n",
    "\n",
    "        return result, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    #전처리의 다양한 종류를 여기서 적용해준다.\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomData(image_list, transform) #이미지에 대한 경로, 일괄적으로 적용할 전처리\n",
    "dataloader = DataLoader(dataset = dataset,\n",
    "                        batch_size = 25,\n",
    "                        shuffle = True,\n",
    "                        drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)\n",
    "batch = next(dataiter)\n",
    "\n",
    "images, labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 7.54967737197876\n",
      "Epoch 10, Loss: 6.5164384841918945\n",
      "Epoch 20, Loss: 5.67962646484375\n",
      "Epoch 30, Loss: 4.988002777099609\n",
      "Epoch 40, Loss: 4.406221866607666\n",
      "Epoch 50, Loss: 3.9095664024353027\n",
      "Epoch 60, Loss: 3.4804630279541016\n",
      "Epoch 70, Loss: 3.106175184249878\n",
      "Epoch 80, Loss: 2.7772700786590576\n",
      "Epoch 90, Loss: 2.486595630645752\n"
     ]
    }
   ],
   "source": [
    "# Matplotlib로 첫 번째 데이터 배치 출력\n",
    "# 이미지가 배치 (N, C, H, W) 형태라고 가정 (예: N=25, C=3, H=224, W=224)\n",
    "def imshow(img, title=None):\n",
    "    \"\"\"이미지 시각화를 위한 함수\"\"\"\n",
    "    img = img.permute(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "    plt.imshow(img)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "# 배치의 첫 번째 이미지 출력\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(5, 5, i + 1)  # 5x5 그리드 생성 (25개의 이미지)\n",
    "    imshow(images[i])\n",
    "    plt.title(f\"Label: {labels[i].item()}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
