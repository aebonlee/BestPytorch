{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 실전 4 : 데이터를 활용한 감성분석모델\n",
    "### 4-1. 감성분석모델 쌓기\n"
   ],
   "id": "d9ee30e6744c5aca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import math\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ],
   "id": "1eafab01bd4f7e7f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a381ffaa-4789-4c2a-ba28-d03a0c4137eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size,\n",
    "                 n_layers=1, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.embed = nn.Embedding(input_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, n_layers,\n",
    "                          dropout=dropout, bidirectional=True)\n",
    "\n",
    "    def forward(self, src, hidden=None):\n",
    "        embedded = self.embed(src)\n",
    "        outputs, hidden = self.gru(embedded, hidden)\n",
    "        # sum bidirectional outputs\n",
    "        outputs = (outputs[:, :, :self.hidden_size] +\n",
    "                   outputs[:, :, self.hidden_size:])\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        timestep = encoder_outputs.size(0)\n",
    "        h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1)  # [B*T*H]\n",
    "        attn_energies = self.score(h, encoder_outputs)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        # [B*T*2H]->[B*T*H]\n",
    "        energy = F.relu(self.attn(torch.cat([hidden, encoder_outputs], 2)))\n",
    "        energy = energy.transpose(1, 2)  # [B*H*T]\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)  # [B*1*H]\n",
    "        energy = torch.bmm(v, energy)  # [B*1*T]\n",
    "        return energy.squeeze(1)  # [B*T]\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, output_size,\n",
    "                 n_layers=1, dropout=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embed = nn.Embedding(output_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout, inplace=True)\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size + embed_size, hidden_size,\n",
    "                          n_layers, dropout=dropout)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, input, last_hidden, encoder_outputs):\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        embedded = self.embed(input).unsqueeze(0)  # (1,B,N)\n",
    "        embedded = self.dropout(embedded)\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attention(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (B,1,N)\n",
    "        context = context.transpose(0, 1)  # (1,B,N)\n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat([embedded, context], 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        output = output.squeeze(0)  # (1,B,N) -> (B,N)\n",
    "        context = context.squeeze(0)\n",
    "        output = self.out(torch.cat([output, context], 1))\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(1)\n",
    "        max_len = trg.size(0)\n",
    "        vocab_size = self.decoder.output_size\n",
    "        outputs = Variable(torch.zeros(max_len, batch_size, vocab_size)).cuda()\n",
    "\n",
    "        encoder_output, hidden = self.encoder(src)\n",
    "        hidden = hidden[:self.decoder.n_layers]\n",
    "        output = Variable(trg.data[0, :])  # sos\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden, attn_weights = self.decoder(\n",
    "                    output, hidden, encoder_output)\n",
    "            outputs[t] = output\n",
    "            is_teacher = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.data.max(1)[1]\n",
    "            output = Variable(trg.data[t] if is_teacher else top1).cuda()\n",
    "        return outputs"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate(model, val_iter, vocab_size, DE, EN):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        pad = EN.vocab.stoi['<pad>']\n",
    "        total_loss = 0\n",
    "        for b, batch in enumerate(val_iter):\n",
    "            src, len_src = batch.src\n",
    "            trg, len_trg = batch.trg\n",
    "            src = src.data.cuda()\n",
    "            trg = trg.data.cuda()\n",
    "            output = model(src, trg, teacher_forcing_ratio=0.0)\n",
    "            loss = F.nll_loss(output[1:].view(-1, vocab_size),\n",
    "                                   trg[1:].contiguous().view(-1),\n",
    "                                   ignore_index=pad)\n",
    "            total_loss += loss.data.item()\n",
    "        return total_loss / len(val_iter)\n",
    "\n",
    "\n",
    "def train(e, model, optimizer, train_iter, vocab_size, grad_clip, DE, EN):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pad = EN.vocab.stoi['<pad>']\n",
    "    for b, batch in enumerate(train_iter):\n",
    "        src, len_src = batch.src\n",
    "        trg, len_trg = batch.trg\n",
    "        src, trg = src.cuda(), trg.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        loss = F.nll_loss(output[1:].view(-1, vocab_size),\n",
    "                               trg[1:].contiguous().view(-1),\n",
    "                               ignore_index=pad)\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data.item()\n",
    "\n",
    "        if b % 100 == 0 and b != 0:\n",
    "            total_loss = total_loss / 100\n",
    "            print(\"[%d][loss:%5.2f][pp:%5.2f]\" %\n",
    "                  (b, total_loss, math.exp(total_loss)))\n",
    "            total_loss = 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parse_arguments()\n",
    "    hidden_size = 512\n",
    "    embed_size = 256\n",
    "    assert torch.cuda.is_available()\n",
    "\n",
    "    print(\"[!] preparing dataset...\")\n",
    "    train_iter, val_iter, test_iter, DE, EN = load_dataset(args.batch_size)\n",
    "    de_size, en_size = len(DE.vocab), len(EN.vocab)\n",
    "    print(\"[TRAIN]:%d (dataset:%d)\\t[TEST]:%d (dataset:%d)\"\n",
    "          % (len(train_iter), len(train_iter.dataset),\n",
    "             len(test_iter), len(test_iter.dataset)))\n",
    "    print(\"[DE_vocab]:%d [en_vocab]:%d\" % (de_size, en_size))\n",
    "\n",
    "    print(\"[!] Instantiating models...\")\n",
    "    encoder = Encoder(de_size, embed_size, hidden_size,\n",
    "                      n_layers=2, dropout=0.5)\n",
    "    decoder = Decoder(embed_size, hidden_size, en_size,\n",
    "                      n_layers=1, dropout=0.5)\n",
    "    seq2seq = Seq2Seq(encoder, decoder).cuda()\n",
    "    optimizer = optim.Adam(seq2seq.parameters(), lr=args.lr)\n",
    "    print(seq2seq)\n",
    "\n",
    "    best_val_loss = None\n",
    "    for e in range(1, args.epochs+1):\n",
    "        train(e, seq2seq, optimizer, train_iter,\n",
    "              en_size, args.grad_clip, DE, EN)\n",
    "        val_loss = evaluate(seq2seq, val_iter, en_size, DE, EN)\n",
    "        print(\"[Epoch:%d] val_loss:%5.3f | val_pp:%5.2fS\"\n",
    "              % (e, val_loss, math.exp(val_loss)))\n",
    "\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if not best_val_loss or val_loss < best_val_loss:\n",
    "            print(\"[!] saving model...\")\n",
    "            if not os.path.isdir(\".save\"):\n",
    "                os.makedirs(\".save\")\n",
    "            torch.save(seq2seq.state_dict(), './.save/seq2seq_%d.pt' % (e))\n",
    "            best_val_loss = val_loss\n",
    "    test_loss = evaluate(seq2seq, test_iter, en_size, DE, EN)\n",
    "    print(\"[TEST] loss:%5.2f\" % test_loss)"
   ],
   "id": "f282ab5fc4d8ea5f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
